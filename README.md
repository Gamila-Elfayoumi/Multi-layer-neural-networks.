# Multi-layer-neural-networks.
In the deep learning we donâ€™t just use one hidden layer, but we use many successive layers.
In this repository we will write the code to calcculate Multiple hidden layers with ReLU Acyivation function. 
The input data has been preloaded as input_data.
The nodes in the first hidden layer are called node_0_0 and node_0_1.
Their weights are pre-loaded as weights['node_0_0'] and weights['node_0_1'] respectively.
The nodes in the second hidden layer are called node_1_0 and node_1_1. 
Their weights are pre-loaded as weights['node_1_0'] and weights['node_1_1'] respectively.
We then create a model output from the hidden nodes using weights pre-loaded as weights['output'].
